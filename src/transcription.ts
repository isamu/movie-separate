import OpenAI from 'openai';
import { createReadStream } from 'fs';
import { Beat, BilingualText } from './types.js';

// OpenAIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’é…å»¶åˆæœŸåŒ–
let openai: OpenAI;

function getOpenAIClient(): OpenAI {
  if (!openai) {
    if (!process.env.OPENAI_API_KEY) {
      throw new Error(
        'Missing OPENAI_API_KEY environment variable. Please create a .env file with your OpenAI API key.'
      );
    }
    openai = new OpenAI({
      apiKey: process.env.OPENAI_API_KEY,
    });
  }
  return openai;
}

export interface TranscriptionWithTimestamps {
  text: string;
  segments?: Array<{
    start: number;
    end: number;
    text: string;
  }>;
}

/**
 * Whisper APIã§éŸ³å£°ã‚’æ–‡å­—èµ·ã“ã—ï¼ˆã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ä»˜ãï¼‰
 */
export async function transcribeAudio(
  audioPath: string
): Promise<string> {
  const client = getOpenAIClient();
  const transcription = await client.audio.transcriptions.create({
    file: createReadStream(audioPath),
    model: 'whisper-1',
    language: 'ja',
  });

  return transcription.text;
}

/**
 * Whisper APIã§éŸ³å£°ã‚’æ–‡å­—èµ·ã“ã—ï¼ˆverbose_jsonå½¢å¼ã§ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—å–å¾—ï¼‰
 */
export async function transcribeAudioWithTimestamps(
  audioPath: string
): Promise<TranscriptionWithTimestamps> {
  const client = getOpenAIClient();
  const transcription = await client.audio.transcriptions.create({
    file: createReadStream(audioPath),
    model: 'whisper-1',
    language: 'ja',
    response_format: 'verbose_json',
    timestamp_granularities: ['segment'],
  });

  return {
    text: transcription.text,
    segments: (transcription as any).segments,
  };
}

export interface SpeakerSegment {
  speaker: string;
  text: string;
  startTime?: number;
  endTime?: number;
}

/**
 * GPT-4oã‚’ä½¿ã£ã¦è©±è€…ã‚’è­˜åˆ¥
 * ä¼šè©±ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚„å£èª¿ã‹ã‚‰è©±è€…ã‚’æ¨å®š
 */
export async function identifySpeakers(
  transcriptionText: string
): Promise<SpeakerSegment[]> {
  try {
    const client = getOpenAIClient();
    const completion = await client.chat.completions.create({
      model: 'gpt-4o',
      messages: [
        {
          role: 'system',
          content: `You are an expert at analyzing conversation transcripts and identifying different speakers.
Parse the given Japanese conversation and separate it into individual utterances with speaker labels.
Return ONLY a valid JSON object with a "speakers" array containing objects with "speaker" and "text" fields.
Use speaker names like "è©±è€…A", "è©±è€…B", etc. for Japanese conversations.
If you cannot identify multiple speakers, return all text under one speaker.

Example format:
{
  "speakers": [
    {"speaker": "è©±è€…A", "text": "ã“ã‚“ã«ã¡ã¯"},
    {"speaker": "è©±è€…B", "text": "ã¯ã„ã€ã“ã‚“ã«ã¡ã¯"}
  ]
}`,
        },
        {
          role: 'user',
          content: `Please analyze this conversation transcript and identify the different speakers:\n\n${transcriptionText}`,
        },
      ],
      response_format: { type: 'json_object' },
    });

    const result = JSON.parse(completion.choices[0].message.content || '{"speakers":[]}');

    if (!result.speakers || result.speakers.length === 0) {
      return [{ speaker: 'è©±è€…A', text: transcriptionText }];
    }

    return result.speakers;
  } catch (error) {
    console.warn('Failed to identify speakers:', error);
    return [{ speaker: 'è©±è€…A', text: transcriptionText }];
  }
}

/**
 * ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ä»˜ãæ–‡å­—èµ·ã“ã—ã‹ã‚‰ä¸»è¦ãªè©±è€…ã‚’æ¨å®š
 */
export async function identifyMainSpeaker(
  transcription: TranscriptionWithTimestamps
): Promise<string> {
  const speakerSegments = await identifySpeakers(transcription.text);

  if (speakerSegments.length > 0) {
    return speakerSegments[0].speaker;
  }

  return 'è©±è€…A';
}

/**
 * æ—¥æœ¬èªãƒ†ã‚­ã‚¹ãƒˆã‚’è‹±èªã«ç¿»è¨³
 */
export async function translateToEnglish(japaneseText: string): Promise<string> {
  try {
    const client = getOpenAIClient();
    const completion = await client.chat.completions.create({
      model: 'gpt-4o-mini',
      messages: [
        {
          role: 'system',
          content: 'You are a professional translator. Translate the given Japanese text to natural English. Only return the translated text, nothing else.',
        },
        {
          role: 'user',
          content: japaneseText,
        },
      ],
    });

    return completion.choices[0].message.content || japaneseText;
  } catch (error) {
    console.warn('Failed to translate to English:', error);
    return japaneseText; // ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ç¿»è¨³å¤±æ•—æ™‚ã¯å…ƒã®ãƒ†ã‚­ã‚¹ãƒˆã‚’è¿”ã™
  }
}

/**
 * éŸ³å£°ã‚’æ–‡å­—èµ·ã“ã—ã—ã¦æ—¥è‹±ä¸¡æ–¹ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’è¿”ã™
 */
export async function transcribeAudioBilingual(audioPath: string): Promise<BilingualText> {
  const japaneseText = await transcribeAudio(audioPath);
  console.log(`    ğŸŒ Translating to English...`);
  const englishText = await translateToEnglish(japaneseText);

  return {
    ja: japaneseText,
    en: englishText,
  };
}
